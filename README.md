# Infant-Cry-Detection-using-CNN

# Overview

Infant Cry Detection using CNN is a deep learning-based system designed to classify different types of infant cries—such as hunger, pain, discomfort, or sleepiness—based on audio recordings. By converting audio into spectrograms, the system uses Convolutional Neural Networks (CNNs) to learn and detect emotional patterns in a baby's cry, enabling early intervention and better care.

# Features

- Audio-based classification of infant cries
- Spectrogram and MFCC feature extraction
- CNN architecture trained on labeled cry audio
- High accuracy and real-time prediction capability
- Potential for smart baby monitors and healthcare support

# Implementation

- Audio Preprocessing: Convert raw .wav files into Mel-spectrograms or MFCCs
- Model Architecture: A CNN designed to process spectrogram images
- Training: Model trained using cross-entropy loss and Adam optimizer
- Evaluation: Accuracy, precision, recall, and confusion matrix
- Prediction: Real-time cry type prediction from new audio samples
